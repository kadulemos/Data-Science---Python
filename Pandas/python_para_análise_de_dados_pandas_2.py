# -*- coding: utf-8 -*-
"""Python_para_Análise_de_Dados_PANDAS_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HI9eDcX4y1r5ksir7TD5TgzRfkh4OeWx

<h2>Mais recursos para trabalhar com grandes bases de dados</h2>

1. Tente trabalhar apenas com as colunas que você vai realmente precisar.
2. Atente para o tipo de dado de cada coluna.
3. Visualize qual o sepador usado para separar os dados.


**Dica:** Se estiver no **Linux** use o comando head para ler as 5 primeiras linhas do arquivo:

`head -n 5 dataset.csv`
"""

!head -n 5 '/content/drive/My Drive/Colab Notebooks/ Data Science - Minerando Dados/datasets/kc_house_data.csv'

"""**Dica:** Se estiver no **Windows** abra o prompt do *PowerShell* e use o comando abaixo:

`gc log.txt -head 5`
"""

import pandas as pd

# Ler a base com o parâmetro nrows
# Difere do comando !head, por esse realizar a leitura do arquivo na memória
df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/ Data Science - Minerando Dados/datasets/kc_house_data.csv', sep=',', nrows=5)

df

"""Exporte o nome das colunas para usar no parâmetro `usecols`"""

df.columns.tolist()

df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/ Data Science - Minerando Dados/datasets/kc_house_data.csv', usecols=['id', 'date', 'price', 'bedrooms', 'bathrooms', 'sqft_lot', 'floors', 'waterfront'])

df.head()

"""Lendo as colunas por posições"""

df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/ Data Science - Minerando Dados/datasets/kc_house_data.csv', usecols=[0,1,2,3,4,5])

df.head()

"""Ler o arquivo completo e veja o uso de memória"""

df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/ Data Science - Minerando Dados/datasets/kc_house_data.csv', sep=',')

df.info()

"""Leia todas as colunas exceto algumas"""

data = '/content/drive/My Drive/Colab Notebooks/ Data Science - Minerando Dados/datasets/kc_house_data.csv'
df = pd.read_csv(data,usecols= lambda column : column not in ['sqt_living','sqft_lot','floors'])

df.info()

"""<h2>Trabalhe com os tipos de dados adeqaudos</h2>

* Atenção para os tipos de dados *object*
* Dados que são categóricos podem receber o tipo de dados *category*
"""

df = pd.read_csv("https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv")

df.info()

"""COnvertendo os tipos de dados"""

df.Sex = df.Sex.astype('category')
df.Embarked = df.Embarked.astype('category')
df.Survived = df.Survived.astype('category')
df.Pclass = df.Pclass.astype('category')
df.PassengerId = df.PassengerId.astype ('int32')
df.Parch = df.Parch.astype('int32')
df.SibSp = df.SibSp.astype('int32')

"""Veja o uso da memória"""

df.info()

"""* Quase 50% de ganho no uso da memória

Converta colunas em tempo de leitura
"""

data = "https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv"
df = pd.read_csv(data, dtype= {"Embarked": "category", "Survived": "category", "Parch": "int32"})

df.info()

"""<h2>Consultando um Dataset</h2>

* Podemos fazer **consultas** em um dataframe, isso se assemelha a linguagem SQL.
* Existem métodos interessantes para fazer consultas usando operadores lógicos (>,<,==).
* Além disso podemos fazer consultas usando instruções de agrupamento, por exemoplo.
* Isso da muita flexibilidade para o Cientista de Dados na hora de explorar da base de dados.
"""

df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/ Data Science - Minerando Dados/datasets/kc_house_data.csv', sep=',')

# Conta a quantidade de valores únicos
pd.value_counts(df['bedrooms'])

# Método loc() é usado para visualizar informações do dataset
# Este método recebe uma lista por parâmetro e retorna o resultado da consulta
# Consulta imóveis com 3 quartos
df.loc[df['bedrooms'] == 3]

# Usando o método loc() junto com o operador &
# Consulta imóveis com 3 quartos e com o número de banheiros maior que 2
df.loc[(df['bedrooms'] == 3) & (df['bathrooms'] > 2)]

# O método sort_values() ordena o dataset pela coluna 'price' em ordem descrescente
# Apenas o retorno da query será ordenado, não a organização do dataset
df.sort_values(by='price', ascending=False)

# Usando o método count() para contar o número de linhas de uma query
df[df['bedrooms'] == 4].count()

"""<h2>Alterando o Dataset</h2>"""

# Adicionando uma coluna ao Dataframe
df['size'] = (df['bedrooms'] * 20)

# Visualizando o conteúdo da coluna criada
df['size'].head()

# Criando uma função ára processamento de dados
def categoriza(s):
  if s >= 80:
    return 'Big'
  elif s >= 60:
    return 'Medium'
  elif s >= 40:
    return 'Small'

# Criando uma nova coluna a partir do procesamento realizado
df['cat_size'] = df['size'].apply(categoriza)

# Visualizando a nova coluna criada
df['cat_size'].head()

# Visualizando a nova coluna com o método value_counts
pd.value_counts(df['cat_size'])

# O método drop é usado para excluir dados no dataframe
# A opção axis=1 define que queremos excluir uma coluna e não uma linha
# O parâmetro inplace define que a alteração irá modificar o objeto em memória

df.drop(['cat_size'], axis=1, inplace=True)

df.head()

# Apagando a coluna 'size'
df.drop(['size'], axis=1, inplace=True)

df.head()

"""**Apagando linhas baseado em Condições Lógicas**"""

# Dropa linhas com bedrooms maiores que 30
df.drop(df[df.bedrooms > 30].index, inplace=True)

pd.value_counts(df['bedrooms'])

